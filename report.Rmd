---
title: "ReportA2.rmd"
author: "Shreysa Sharma"
date: "9/29/2017"
output: html_document
---
---
title: "Assignment A2"
author: "Shreysa Sharma"
date: "9/28/2017"
output:
  html_document: default
  pdf_document: default
---


#### Specifications of host execution Environment
Attribute                         | Value
----------------------------------|-------------------------------
Java Version                      | 1.8.0_102
Java(TM) SE Runtime Environment   | (build 1.8.0_102-b14)
Java HotSpot(TM) 64-Bit Server VM | (build 25.102-b14, mixed mode)
Model Identifier                  |	MacBookPro11,2
Processor Name                    |	Intel Core i7
Processor Speed                   |	2.2 GHz
Number of Processors              |	1
Total Number of Cores             |	4
L2 Cache (per Core)               |	256 KB
L3 Cache                          |	6 MB
Memory                            | 16 GB

#### Specifications of Execution Environment
Attribute                            | Value
-------------------------------------|-------------------------------
Name                                 | cloudera-quickstart--vm-5.12.0-0-virtualbox
Operating System                  | Red Hat (64 bit)
Base Memory                       | 6144 MB 
Processors                        |	4
Boot Order                        |	Hard Disk, Optical
Controller                        |	IDE Controller
IDE Primary Master                |	cloudera-quickstart-vm-5.12.0-0-virtualbox-disk1.vmdk (Normal = 64.00 GB) 
IDE Secondary Master              |	Optical Drive VBoxGuestAdditions.iso (56.74 GB)
Adapter                           | Intel Pro/1000 MT Desktop (NAT)
Hadoop version                    | 2.6.0-cdh5.12.0

### Summary of the design of evaluated program

The current implementation involves chaining of 2 map reduce jobs. The first map job emits the letter occurances while the reduce job calculates the total letter occurances and then computes the scores as per the requirements given in assignment A0. It then dumps this data into an intermediate file. Since there can be multiple reducers we can have multiple intermediate files, these intermediate files are then merged to provide input to the second map job called the KNeighborhoodMapper. The second map job then reads and calculates the word scores of the input files and caches in a hashmap while the second reduce job called the KNeighborhoodReducer calculates the KNeighborhood Mean scores. 

The above implementation has been done on a cloudera pseudo distributed cluster which performs on a single node. 

The code was implemented in 2 ways:
(i) The first implementation loaded the entire file as a massive string into memory and send it to the mapper for processing. This worked for the dataset provided for task A0-A1 but attempting to run that code on the large dataset caused the application to fail due to insufficient Heap memory. Even increasing the heap to 8GB did not solve the issue. Preventing splitting is anti pattern to map reduce but it satisfyies some aspects of the code.

(ii) In the second implementation depending upon the K value passed, "K Ghost words"" are added to the beginning and end of each record sent to mapper, then the mapper starts processIng the file at the k'th word and stops k words before the end of the record. This overlap between records allows for correct kneighbor score calculation. In this approach only 1 record worth of memory is occupied per mapper, the application does not exhaust the heap memory and is able to handle large datasets such as the one provided for task A2.

One of the weaknesses of the current implementation is that the output is not in csv format. This formatting can be achieved by using a suitably modifies TextOutputFormat class.

#### Analysis

##### Table 1: Map reduce iterations for K=2 for A2 dataset

```{r}
library(ggplot2)
Map_reduce_run<-read.csv("output/Map_reduce_run.csv")
knitr::kable(Map_reduce_run)
```

The above table represents the total time taken and total average time of 3 runs of map reduce job in seconds. Each run takes about 99 minutes to finish.


##### Plot 1: Total Time Taken in seconds vs Num of runs

```{r}
ggplot(Map_reduce_run, aes(x=Runs, y=total_time_taken, color="Total Average Time")) + 
  geom_point() +
  ylab("Total time taken by map reduce job in seconds") + 
  xlab("Number of runs") + 
  scale_y_continuous(breaks=seq(5750,6250,250),  limits = c(5750,6250))+
  scale_x_continuous(breaks=seq(0,4,1), limits = c(0,4))
```

Plot 1 is the graphical representation of Table 1. The graph shows that each job takes about 99 to 100 minutes to complete on the big dataset provided for assignment A2. As mentioned above in the summary of design, there are 2 map reduce jobs chained to get the KNeighborhood mean scores.

##### Plot 2: Total Average time in seconds vs Num Threads (k = 2)

```{r}
performance_data_k2<-read.csv("output/results_kval_2.csv")
ggplot(performance_data_k2, aes(x=num_threads, y=total_avg_s, color="Total Average Time")) + 
  geom_point() +
  ylab("Total Average Time in seconds (compared to serial version)") + 
  xlab("Number of threads") + 
  scale_y_continuous(breaks=seq(0,60,5), limits = c(5, 60)) +
  scale_x_continuous(breaks=seq(0,16,1), limits = c(0,16))
```

Plot 2 represents the total average time taken by sequential and threaded versions plotted against number of threads when K value is 2. As per Amdahl's law, the theoretical speedup in latency of the execution of a program in function of the number of processors executing it, for different number of threads/processors. The speedup is limited by the serial part of the program. For example, if 95% of the program can be parallelized, the theoretical maximum speedup using parallel computing would be 20 times, likewise if 50% of the program can be parallelized - the therotical maximum speedup using parallel computing would be 2 times the time taken by serial version. Plot 2 thereby signifies the same speed up representations. (Answer to point 2 in assignment)
(Above statement taken from https://en.wikipedia.org/wiki/Amdahl%27s_law)

##### Table 2: Dataset size and Total time taken comparison

```{r}
library(ggplot2)
comparison<-read.csv("output/dataset_time_comparison.csv")
knitr::kable(comparison)
```


The A2 dataset consists of 16 files of about 541 MB each for a total corpus size of 8656 MB, the A0-A1 dataset is of 74 MB. The A2 dataset is therefore ~117 times bigger than the A0-A1 dataset. The average time taken for a map reduce job on the A0-A1 dataset is ~392 seconds and the average time for a job on the A2 dataset is 5972 seconds, therefore the A2 job took ~15 times the time taken for the A0-A1 job even though the dataset is about ~117 times bigger. This demonstarates the power of map reduce over very very large datasets.

### Conclusion

Over the course of this assignment, it was clear that writing a map reduce program to handle large dataset problems is indeed easier as compared to the same task done by threads. On running this developed application over both the dataset provided for A0 and A2, the output generated appear to be the same that suggests that the A2 dataset is multiple copies of A0-A1 dataset. 
However, it is necassary to understand the API, architecture and limitations of HADOOP (map reduce) to fully exploit this powerful framework.